{"ast":null,"code":"// import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\n// import React from 'react';\n\n// const Dictaphone = () => {\n//   const {\n//     transcript,\n//     listening,\n//     resetTranscript,\n//     browserSupportsSpeechRecognition\n//   } = useSpeechRecognition();\n\n//   if (!browserSupportsSpeechRecognition) {\n//     return <span>Browser doesn't support speech recognition.</span>;\n//   }\n\n//   return (\n//     <div>\n//       <p>Microphone: {listening ? 'on' : 'off'}</p>\n//       <button onClick={SpeechRecognition.startListening}>Start</button>\n//       <button onClick={SpeechRecognition.stopListening}>Stop</button>\n//       <button onClick={resetTranscript}>Reset</button>\n//       <p>{transcript}</p>\n//     </div>\n//   );\n// };\n// export default Dictaphone;","map":{"version":3,"names":[],"sources":["C:/Users/Blandus/Desktop/chatapp/src/components/DIctaphone.jsx"],"sourcesContent":["// import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\r\n\r\n// import React from 'react';\r\n\r\n// const Dictaphone = () => {\r\n//   const {\r\n//     transcript,\r\n//     listening,\r\n//     resetTranscript,\r\n//     browserSupportsSpeechRecognition\r\n//   } = useSpeechRecognition();\r\n\r\n//   if (!browserSupportsSpeechRecognition) {\r\n//     return <span>Browser doesn't support speech recognition.</span>;\r\n//   }\r\n\r\n//   return (\r\n//     <div>\r\n//       <p>Microphone: {listening ? 'on' : 'off'}</p>\r\n//       <button onClick={SpeechRecognition.startListening}>Start</button>\r\n//       <button onClick={SpeechRecognition.stopListening}>Stop</button>\r\n//       <button onClick={resetTranscript}>Reset</button>\r\n//       <p>{transcript}</p>\r\n//     </div>\r\n//   );\r\n// };\r\n// export default Dictaphone;"],"mappings":"AAAA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA"},"metadata":{},"sourceType":"module","externalDependencies":[]}